https://leetcode.com/problems/combination-sum/description/

Given an array of distinct integers candidates and a target integer target, return a list of all unique combinations of candidates where the chosen numbers sum to target. You may return the combinations in any order.

The same number may be chosen from candidates an unlimited number of times. Two combinations are unique if the frequency of at least one of the chosen numbers is different.

The test cases are generated such that the number of unique combinations that sum up to target is less than 150 combinations for the given input.

Example 1:

Input: candidates = [2,3,6,7], target = 7
Output: [[2,2,3],[7]]
Explanation:
2 and 3 are candidates, and 2 + 2 + 3 = 7. Note that 2 can be used multiple times.
7 is a candidate, and 7 = 7.
These are the only two combinations.
Example 2:

Input: candidates = [2,3,5], target = 8
Output: [[2,2,2,2],[2,3,3],[3,5]]
Example 3:

Input: candidates = [2], target = 1
Output: []
 

Constraints:

1 <= candidates.length <= 30
2 <= candidates[i] <= 40
All elements of candidates are distinct.
1 <= target <= 40

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
recursive approach : 
Time and Space Complexity Analysis for combinationSum()

Given:

* `n` = number of candidates (`candidates.size()`)
* `T` = target sum (`target`)
* `c_min` = smallest element in `candidates`

1. Time Complexity:

* Maximum recursion depth, h = T / c\_min.
* At each recursive call there are two branches: include or exclude.
* Rough number of calls grows like 2^h.
* Each valid solution (leaf) may take O(h) to copy into the result list.

Overall:

```
Time = O(2^(T / c_min) * (T / c_min))
```

This is exponential in T / c\_min.

2. Space Complexity:

* Auxiliary (call stack + working vector): O(h) = O(T / c\_min).
* Output storage (result list of all combinations): if K = number of solutions, storing them takes O(K \* h).

Overall auxiliary space (excluding output):

```
Space_aux = O(T / c_min)
```

Including output:

```
Space_total = O(K * (T / c_min))
```


_______
think about what if we only do the include and exclude and move forward the index everytime it will be something liek this : 

If you change your recursion so that **both** the “include” and the “exclude” branches advance the index, then:

1. **Recursion depth** is at most `n` (since each call does `i+1`).
2. **Branching factor** is 2 at every level (include-or-exclude).

---

### Tree size

A full binary tree of height `n` has about

$$
  \sum_{k=0}^{n} 2^k \;=\; 2^{n+1}-1 \;=\; O(2^n)
$$

nodes (i.e. recursive calls).

---

### Time complexity

* **Checking / arithmetic work** at each call is O(1).
* When you hit `sum == target`, you copy the current vector `v` of length ≤ n in O(n).
* In the absolute worst case (no pruning by `sum >= target`), you could reach all 2ⁿ leaves and copy at each leaf, giving

  $$
    O\bigl(2^n \times n\bigr).
  $$
* If you ignore the cost of copying the solution into `res`, the bare number of calls is O(2ⁿ).

So you can say:

> **Time:** O(2ⁿ)
> **Time (including vector‐copying):** O(2ⁿ · n)

---

### Space complexity

* **Auxiliary (call stack + working vector):** O(n)
* **Total (including stored results):** O(K·n), where K is the number of valid combinations found.

---

**Bottom line:** by moving the index forward in both branches you reduce the “depth” contribution from T/cₘᵢₙ down to n, but the algorithm remains exponential—O(2ⁿ) in the number of candidates.

so time and space is kinda similarly we are exploring in both of them right ?