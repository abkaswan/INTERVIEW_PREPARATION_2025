https://www.geeksforgeeks.org/problems/frogs-and-jumps--170647/0

Frogs and Jumps
N frogs are positioned at one end of the pond. All frogs want to reach the other end of the pond as soon as possible. The pond has some leaves arranged in a straight line. Each frog has the strength to jump exactly K leaves. For example, a  frog having strength 2 will visit the leaves 2, 4, 6, ...  etc. while crossing the pond.

Given the strength of each frog and the number of leaves, your task is to find the number of leaves that not be visited by any of the frogs when all frogs have reached the other end of the pond. 

Example 1:

Input:
N = 3
leaves = 4
frogs[] = {3, 2, 4} 
Output: 1
Explanation:
Leaf 1 will not be visited by any frog.
Example 2:

Input: 
N = 3
leaves = 6
frogs[] = {1, 3, 5} 
Output: 0
Explanation: 
First frog will visit all the leaves so no 
leaf is left unvisited.
Your Task:
Complete the function unvisitedLeaves() which takes the integers N, leaves and the array frogs as the input parameters, and returns the number of unvisited leaves.

Expected Time Complexity: O(N*log(leaves))
Expected Auxiliary Space: O(leaves)

Constraints:
1 ≤ N, leaves, frogs[i] ≤ 105



______________
the iterative solution is optimised and here is the explanation why the time complexity is thw ay it is : 


Let’s revisit the marking loop more carefully. With your “skip if `v[frogs[i]]` is already true” check, you are effectively implementing a sieve‐like pattern: as soon as a smaller frog’s step size has already marked the exact position `k = frogs[i]`, you know that all multiples of `k` have also already been covered, so you skip the entire inner loop for that frog.

Concretely:

for (int i = 0; i < N; i++) {
    int step = frogs[i];
    if (step <= leaves && !v[step]) {
        // “step” hasn’t been marked yet, so we must go mark
        // every multiple of step up to “leaves”.
        for (int j = step; j <= leaves; j += step) {
            v[j] = true;
        }
    }
}


1. Why it’s NOT O(N·log(leaves)
   A naive upper bound of “for each of N frogs, do about `leaves/step` work, and if steps are roughly distributed you get \~`leaves·(1 + 1/2 + 1/3 + … + 1/N)` ≈ `leaves·log(N)`” is too pessimistic here. The key is that **many frogs get skipped** because their exact step position `v[step]` was already marked by some smaller divisor. This is exactly the same idea behind the Sieve of Eratosthenes:

   * If `frogs[i] = p` is prime, and no smaller frog had step dividing `p`, then you do ∼`leaves/p` markings.
   * As soon as some smaller frog `d` divides `p` (so `p` is a multiple of `d`), you see `v[p] == true` and skip the entire inner loop for that `p`.

   In the “worst possible arrangement,” every frog’s step is a prime (or behaves like a new co-prime), so you end up marking multiples of each prime exactly once. Summing over primes p ≤ (roughly) `leaves` gives:

   $$
     sum of leaves/p where p<=leaves = leaves.(1/2+1/3+1/5.....) = O(leaves.log(log(leaves)))
   $$

   (This is exactly the same harmonic‐over‐primes bound that shows up in the Sieve’s runtime analysis.)

   * If you simply say “there are at most N frogs (and each prime ≤ `leaves`), then the largest possible N of distinct primes we could have is the number of primes up to `leaves` (≈ `leaves / log(leaves)`), but even in that extreme,
         sum of 1/p where p<=leaves = log(log(leaves))
    So the total marking cost is still bounded by
        O(leaves.log(log(leaves)))
        
   * If you want a slightly coarser (but simpler) bound in terms of **N**, notice that the worst case for “distinct steps” is if your N frogs are the first N primes (or any N co-primes), in which case

     $$
         sum of (1/i-th prime) from i = 1 to N = O(log(log(N-th prime))) = O(log(log(N.logN))) =O(log(logN))
     $$

     Hence a convenient (but slightly looser) statement is

     $$
        Time = O(leaves.log(log(N))+N+leaves) = O(leaves.log(log(N)))  
     $$

     since the final “count unvisited” sweep is O(leaves) and the “`if (step ≤ leaves && !v[step])`” check over N frogs is O(N).

In other words:

* **Tighter (sieve‐style) bound:**
    O(leaves.log(log(leaves)))
* **Weaker but still valid in terms of N:**
    O(leaves.log(log(N)))

Either of those is asymptotically smaller than $N \cdot \log(\text{leaves})$ when N and leaves are both large. The intuitive takeaway is:

* Because you skip any frog whose **exact** `frogs[i]` position was already marked, you only do a “mark multiples of k” pass once for each new “step size” k that wasn’t a multiple of a smaller frog’s step.
* That skipping behavior is exactly what gives the $\log\log$-type factor (just like the Sieve of Eratosthenes) instead of a full $\log(\text{leaves})$ per frog.

---

### ✔️ Space Complexity

* You still only store `vector<bool> v(leaves+1)`, which is O(leaves) extra space.

---

### ✔️ Final Answer

* **Time:**
    O(leaves.log(log(leaves))) (equivalently O(leaves.log(log(N))) if you want to parameterize by N<=leaves)
* **Space:**
 O(leaves)
